{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kB3ViOebJ1Dl"
   },
   "source": [
    "Assignment 3: Image Classification using CNNs\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yz0UcUjYdIkR"
   },
   "source": [
    "In this assignment you will learn about\n",
    "1. The fundamental computations in neural networks for vision, including backpropagation\n",
    "2. The basics of fitting a model for generalization\n",
    "3. Nearest neighbor classifiers\n",
    "\n",
    "**Note:** When you first load this colab webpage, it will be in read-only viewing mode.  To edit and run code, you can either (a) download the Jupyter notebook (\"File\" -> \"Download .ipynb\") to run on your local computer or (b) copy to your Google Drive (\"File\" -> \"Save a copy in Drive...\") to work in the browser and run on a Google Cloud GPU.  If you run locally, you will need to install Tensorflow and it is recommended that you use a GPU for problem 3.2.  If you do not want to use Colab and do not have a local GPU, please let us know.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IScx1TAgmBgV"
   },
   "source": [
    "# 3.0 Nearest neighbor classification (20 points)\n",
    "\n",
    "## 3.0.1 (20 points) \n",
    "Given the following training set of labeled two-dimensional points for binary classification, draw a Voronoi diagram of the output of a 1-nearest neighbor classifier.  Feel free to render the diagram using Python below (do not use scikit-learn or any machine learning libraries to do this) or submit a PDF along with your assignment.\n",
    "\n",
    ">```\n",
    "Point (x,y)  | Label\n",
    "-------------|-------\n",
    "(1,3)        |   +\n",
    "(-4,-2)      |   +\n",
    "(-3,-1.5)    |   -\n",
    "(3,3)        |   -\n",
    "(0,-2)       |   +\n",
    "(-2,0)       |   +\n",
    "(-2,4)       |   -\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Q3U4NGyNqbKG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gggggggggg \n",
      "\n",
      "gggrgggggg \n",
      "\n",
      "gggrgggggg \n",
      "\n",
      "ggrrgggggg \n",
      "\n",
      "ggrggggggr \n",
      "\n",
      "grggggggrr \n",
      "\n",
      "ggggggggrr \n",
      "\n",
      "ggggggggrr \n",
      "\n",
      "rrrrrgggrr \n",
      "\n",
      "rrrrrgggrr \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "## Can render diagram using Python here, if you would like.\n",
    "def distance(x1, x2, y1, y2):\n",
    "    x_diff = x2 - x1\n",
    "    y_diff = y2 - y1 \n",
    "    return np.sqrt((x_diff**2)+(y_diff**2))  \n",
    "\n",
    "def nearest_neighbors(x_idx, y_idx, datapoints, k):\n",
    "    all_dist = []\n",
    "    label = 0\n",
    "    #Go through each datapoint\n",
    "    for point in datapoints:\n",
    "        curr_distance = distance(x_idx, point[0], y_idx, point[1])\n",
    "        #Change to point for debugging\n",
    "        all_dist.append((curr_distance, point[2]))\n",
    "    sorted_dist = sorted(all_dist, key=lambda x:x[0])\n",
    "    k_nn = sorted_dist[:k]\n",
    "    for neighbor in k_nn:\n",
    "        if(neighbor[1] == \"+\"):\n",
    "            label += 1\n",
    "        else:\n",
    "            label -= 1\n",
    "    #print(x_idx,\",\",y_idx,\":\",sorted_dist)\n",
    "    if(label > 0):\n",
    "        return \"+\"\n",
    "    elif(label < 0):\n",
    "        return \"-\"\n",
    "    else:\n",
    "        return nearest_neighbors(x_idx, y_idx, datapoints, k-1)\n",
    "\n",
    "\n",
    "## Can render diagram using Python here, if you would like.\n",
    "#Initialize the datapoints\n",
    "datapoints = [(1, 3, \"+\"), (-4, -2, \"+\"), (-3, -1.5, \"-\"), (3, 3, \"-\"), (0, -2, \"+\"), (-2, 0, \"+\"), (-2, 4, \"-\")]\n",
    "\n",
    "#initialize the boundaries\n",
    "H = W = 5\n",
    "       \n",
    "for i in range(-H,H):\n",
    "    output = \"\"\n",
    "    for j in range(-W,W):\n",
    "        label = nearest_neighbors(j, i, datapoints, 1)\n",
    "        if(label == \"+\"):\n",
    "            plt.plot(j,i, \"g\")\n",
    "            output += \"g\"\n",
    "        elif(label == \"-\"):\n",
    "            plt.plot(j,i, \"r\")\n",
    "            output += \"r\"\n",
    "        else:\n",
    "            print(\"ERROR\")\n",
    "    print(output ,\"\\n\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SLFlhLnW6FJH"
   },
   "source": [
    "## 3.0.2 (5 points, extra) \n",
    "\n",
    "Render for 3-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "MB-Q7MZmRb_w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gggggggggg \n",
      "\n",
      "gggggggggg \n",
      "\n",
      "gggggggggg \n",
      "\n",
      "gggggggggg \n",
      "\n",
      "gggggggggg \n",
      "\n",
      "gggggggggg \n",
      "\n",
      "gggrgggggg \n",
      "\n",
      "rrrggggggg \n",
      "\n",
      "rrgggrrrrr \n",
      "\n",
      "rgggrrrrrr \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(-H,H):\n",
    "    output = \"\"\n",
    "    for j in range(-W,W):\n",
    "        label = nearest_neighbors(j, i, datapoints, 3)\n",
    "        if(label == \"+\"):\n",
    "            plt.plot(j,i, \"g\")\n",
    "            output += \"g\"\n",
    "        elif(label == \"-\"):\n",
    "            plt.plot(j,i, \"r\")\n",
    "            output += \"r\"\n",
    "        else:\n",
    "            print(\"ERROR\")\n",
    "    print(output ,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pqcz4ghVMich"
   },
   "source": [
    "# 3.1 Neural network operations (40 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tOxsGv9H4h4Q"
   },
   "source": [
    "In this section we provide a working example of a convolutional neural network written using basic numpy operations.  Each neural network operation is represented by a Python class with methods *forward()* and *backward()*, which compute activations and gradients, respectively. Your task is to complete certain methods that are left blank.\n",
    "\n",
    "1. 2D Convolution\n",
    "> * Forward\n",
    "> * **Backward (10 points)**\n",
    "2. ReLU\n",
    "> * **Forward (5 points)**\n",
    "> * Backward\n",
    "3. Average pooling\n",
    "> * Forward\n",
    "> * **Backward (5 points)**\n",
    "4. Softmax cross-entropy\n",
    "> * **Forward (10 points)**\n",
    "> * Backward\n",
    "\n",
    "When you complete an operation, you can check your work by executing its cell.  We compare the outputs of your method to that of Tensorflow.\n",
    "\n",
    "Finally, when you have all of the operations completed, you can run a small network for a few iterations of stochastic gradient descent and plot the loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "E7LdJleoh6px"
   },
   "outputs": [],
   "source": [
    "#@title (Hidden utility code: RUN ME FIRST) { display-mode: \"form\" }\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class Variable:\n",
    "  \"\"\"Placeholder for labels and input images\"\"\"\n",
    "  value = 0\n",
    "\n",
    "def cmp_ops(your_op, tf_op, tf_inputs, tf_weights=None):\n",
    "  your_op.forward()\n",
    "  your_op_f_out = your_op.value\n",
    "\n",
    "  with tf.Session().as_default():\n",
    "    tf_op_f_out = tf_op.eval()[0] # Remove the batch dimension\n",
    "\n",
    "  print(\"Forward pass:\")\n",
    "  cmp_tensors(your_op_f_out, tf_op_f_out, verbose=False)\n",
    "\n",
    "  your_op.inputs.dloss_dvalue = np.zeros(your_op.inputs.value.shape)\n",
    "  your_op.dloss_dvalue = np.ones(your_op.value.shape)\n",
    "  your_op.backward()\n",
    "  your_op_g_inputs = your_op.inputs.dloss_dvalue\n",
    "\n",
    "  if tf_weights is not None:\n",
    "    your_op_g_weights = your_op.dloss_dweights\n",
    "    g_inputs, g_weights = tf.gradients(tf.reduce_sum(tf_op), [tf_inputs, tf_weights])\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "      tf_g_inputs_out, tf_g_weights_out = sess.run([g_inputs, g_weights])\n",
    "      tf_g_weights_out = np.transpose(tf_g_weights_out, [3,0,1,2])\n",
    "    \n",
    "    print(\"Gradient wrt inputs:\")\n",
    "    cmp_tensors(your_op_g_inputs, tf_g_inputs_out[0])\n",
    "    print(\"Gradient wrt weights:\")\n",
    "    cmp_tensors(your_op_g_weights, tf_g_weights_out)\n",
    "    \n",
    "  else:\n",
    "    g_inputs = tf.gradients(tf.reduce_sum(tf_op), [tf_inputs])\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "      tf_g_inputs_out = sess.run(g_inputs)\n",
    "\n",
    "    print(\"Gradient wrt inputs:\")\n",
    "    cmp_tensors(your_op_g_inputs, tf_g_inputs_out[0], verbose=False)\n",
    "\n",
    "def cmp_tensors(yours, tfs, verbose=False):\n",
    "  print(\"  Your Op shape: \" + str(yours.shape))\n",
    "  print(\"  TensorFlow Op shape: \" + str(tfs.shape))\n",
    "  print(\"  Values equal: \" + str(np.allclose(tfs, yours, atol=1e-6)))\n",
    "  if verbose:\n",
    "    print(tfs)\n",
    "    print(yours)\n",
    "    \n",
    "inputs = Variable()\n",
    "inputs.value = np.random.normal(size=(10, 10, 3)) # Input image is 10x10x3\n",
    "tf_inputs = tf.constant(inputs.value[np.newaxis, ...], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lms52ZYzdQnA"
   },
   "source": [
    "## 3.1.1 2D Convolution (10 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellView": "code",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "5w_5lVExdNKK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Conv2D...\n",
      "Forward pass:\n",
      "  Your Op shape: (8, 8, 4)\n",
      "  TensorFlow Op shape: (8, 8, 4)\n",
      "  Values equal: True\n",
      "Gradient wrt inputs:\n",
      "  Your Op shape: (10, 10, 3)\n",
      "  TensorFlow Op shape: (10, 10, 3)\n",
      "  Values equal: True\n",
      "Gradient wrt weights:\n",
      "  Your Op shape: (4, 3, 3, 3)\n",
      "  TensorFlow Op shape: (4, 3, 3, 3)\n",
      "  Values equal: True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\"\"\"rows x cols x filters\"\"\"\n",
    "\n",
    "class OpConv2D:\n",
    "  \"\"\"Two-dimensional convolutional layer\"\"\"\n",
    "    \n",
    "  def __init__(self, filters, kernel_size, inputs):\n",
    "    # Shape of the input feature map\n",
    "    input_height = inputs.value.shape[0]\n",
    "    input_width = inputs.value.shape[1]\n",
    "    input_filters = inputs.value.shape[2]\n",
    "    \n",
    "    # Shape of this layer's feature map\n",
    "    self.height = input_height - kernel_size + 1\n",
    "    self.width = input_width - kernel_size + 1\n",
    "    self.filters = filters\n",
    "    \n",
    "    self.inputs = inputs\n",
    "    self.kernel_size = kernel_size\n",
    "    self.weights = np.random.normal(size=(filters, kernel_size, kernel_size, input_filters), scale=0.1)\n",
    "    self.reset_values()\n",
    "    \n",
    "  def reset_values(self):\n",
    "    self.value = np.zeros((self.height, self.width, self.filters))\n",
    "    self.dloss_dvalue = np.zeros(self.value.shape)\n",
    "    self.dloss_dweights = np.zeros(self.weights.shape)\n",
    "    \n",
    "  def forward(self):\n",
    "    # Reset value and gradient at start of forward pass\n",
    "    self.reset_values()\n",
    "    \n",
    "    for y in range(self.height):\n",
    "      for x in range(self.width):\n",
    "        for f in range(self.filters):\n",
    "          z = 0.0\n",
    "          \n",
    "          for ky in range(self.kernel_size):\n",
    "            for kx in range(self.kernel_size):\n",
    "              for kf in range(self.weights.shape[3]):\n",
    "                z += self.inputs.value[y+ky, x+kx, kf] * self.weights[f, ky, kx, kf]\n",
    "                \n",
    "          self.value[y, x, f] = z\n",
    "          \n",
    "  def backward(self):\n",
    "    ## Complete this method, which sets:\n",
    "    ## 1. Partial derivative of the loss with respect to the values of the inputs\n",
    "    ## self.inputs.dloss_dvalue, which is a `height x width x input_filters` tensor\n",
    "    ## 2. Partial derivative of the loss with respect to the weights\n",
    "    ## self.dloss_dweights, which is a `filters x kernel_size x kernel_size x input_filters` tensor\n",
    "    ##\n",
    "    ## This will utilize tensors:\n",
    "    ## 1. The partial with respect to the value of this layer\n",
    "    ## self.dloss_dvalue, a `height x width x filter` tensor\n",
    "    ## 2. The weights of this layer\n",
    "    ## self.weights, a `filters x kernel_size x kernel_size x input_filters` tensor\n",
    "    ## 3. The value of the input layer\n",
    "    ## self.inputs.value, a `height x width x input_filters` tensor\n",
    "    pass\n",
    "    \"\"\"\n",
    "    print(\"input weight:\",self.weights.shape)\n",
    "    print(\"input loss:\",self.dloss_dvalue.shape)  \n",
    "    print(\"input value:\",self.inputs.value.shape)\n",
    "    print(\"output value:\",self.inputs.dloss_dvalue.shape)\n",
    "    print(\"output weight:\",self.dloss_dweights.shape)\n",
    "    \"\"\"\n",
    "    \n",
    "    #print(self.height,\",\",self.width,\",\",self.filters)\n",
    "    for y in range(self.height):\n",
    "      for x in range(self.width):\n",
    "        for f in range(self.filters): \n",
    "          #print(y,\",\",x,\",\",f)  \n",
    "            \n",
    "          #print(self.kernel_size)\n",
    "          for ky in range(self.kernel_size):\n",
    "            for kx in range(self.kernel_size):\n",
    "              for kf in range(self.weights.shape[3]):\n",
    "                self.inputs.dloss_dvalue[y+ky, x+kx, kf] += self.weights[f, ky, kx, kf] * self.dloss_dvalue[y, x, f]\n",
    "                self.dloss_dweights[f, ky, kx, kf] += self.inputs.value[y+ky, x+kx, kf] * self.dloss_dvalue[y, x, f]\n",
    "                \n",
    "  def gradient_step(self, step_size):\n",
    "    self.weights -= step_size * self.dloss_dweights\n",
    "    \n",
    "# Double check that op matches tensorflow\n",
    "print(\"Testing Conv2D...\")\n",
    "op1 = OpConv2D(4, 3, inputs)\n",
    "\n",
    "tf_weights = tf.constant(np.transpose(op1.weights, [1,2,3,0]), dtype=tf.float32)\n",
    "tf_op1 = tf.nn.conv2d(tf_inputs,\n",
    "                      tf_weights,\n",
    "                      [1,1,1,1],\n",
    "                      'VALID')\n",
    "cmp_ops(op1, tf_op1, tf_inputs, tf_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-MdfHCgzdYnx"
   },
   "source": [
    "## 3.1.2 ReLU (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "6cwXENGCC9tm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Relu...\n",
      "Forward pass:\n",
      "  Your Op shape: (10, 10, 3)\n",
      "  TensorFlow Op shape: (10, 10, 3)\n",
      "  Values equal: True\n",
      "Gradient wrt inputs:\n",
      "  Your Op shape: (10, 10, 3)\n",
      "  TensorFlow Op shape: (1, 10, 10, 3)\n",
      "  Values equal: True\n"
     ]
    }
   ],
   "source": [
    "class OpRelu:\n",
    "  \"\"\"Elementwise relu operator\"\"\"\n",
    "    \n",
    "  def __init__(self, inputs):\n",
    "    # Shape of the input feature map\n",
    "    self.input_shape = inputs.value.shape\n",
    "    self.inputs = inputs\n",
    "    self.reset_values()\n",
    "    \n",
    "  def reset_values(self):\n",
    "    self.value = np.zeros(self.inputs.value.shape)\n",
    "    self.dloss_dvalue = np.zeros(self.inputs.value.shape)\n",
    "    \n",
    "  def forward(self):\n",
    "    # Reset value and gradient at start of forward pass\n",
    "    self.reset_values()\n",
    "    height, width, filters = inputs.value.shape \n",
    "    for y in range(self.input_shape[0]):\n",
    "      for x in range(self.input_shape[1]):\n",
    "        for f in range(self.input_shape[2]):\n",
    "          self.value[y, x, f] = max(self.inputs.value[y, x, f], 0)\n",
    "\n",
    "            \n",
    "    ## Complete this code by setting self.value using self.inputs.value\n",
    "    #self.value = self.inputs.value > 0 ? self.inputs.value : 0\n",
    "          \n",
    "  def backward(self):\n",
    "    self.inputs.dloss_dvalue = self.dloss_dvalue * np.greater(self.value, 0.0)\n",
    "                \n",
    "  def gradient_step(self, step_size):\n",
    "    pass    \n",
    "  \n",
    "# Double check that each op matches tensorflow\n",
    "print(\"\\nTesting Relu...\")\n",
    "op2 = OpRelu(inputs)\n",
    "tf_op2 = tf.nn.relu(tf_inputs)\n",
    "cmp_ops(op2, tf_op2, tf_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bz3FdokPdxVx"
   },
   "source": [
    "## 3.1.3 Average Pooling (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "U1-lSilxdh1x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing AvgPool...\n",
      "Forward pass:\n",
      "  Your Op shape: (5, 5, 3)\n",
      "  TensorFlow Op shape: (5, 5, 3)\n",
      "  Values equal: True\n",
      "Gradient wrt inputs:\n",
      "  Your Op shape: (10, 10, 3)\n",
      "  TensorFlow Op shape: (1, 10, 10, 3)\n",
      "  Values equal: True\n"
     ]
    }
   ],
   "source": [
    "class OpAvgPool:\n",
    "  \"\"\"Average pooling layer. Non-overlapping cells.\"\"\"\n",
    "    \n",
    "  def __init__(self, cell_size, inputs):\n",
    "    # Shape of the input feature map\n",
    "    self.input_height = inputs.value.shape[0]\n",
    "    self.input_width = inputs.value.shape[1]\n",
    "    self.input_filters = inputs.value.shape[2]\n",
    "    \n",
    "    # Shape of this layer's feature map\n",
    "    self.height = int((self.input_height + cell_size - 1) / cell_size)\n",
    "    self.width = int((self.input_width + cell_size - 1) / cell_size)\n",
    "    self.filters = self.input_filters\n",
    "    \n",
    "    self.inputs = inputs\n",
    "    self.cell_size = cell_size\n",
    "    self.reset_values()\n",
    "    \n",
    "  def reset_values(self):\n",
    "    self.value = np.zeros((self.height, self.width, self.filters))\n",
    "    self.dloss_dvalue = np.zeros(self.value.shape)\n",
    "    \n",
    "  def forward(self):\n",
    "    # Reset value and gradient at start of forward pass\n",
    "    self.reset_values()\n",
    "    \n",
    "    for y in range(self.height):\n",
    "      for x in range(self.width):\n",
    "        for f in range(self.filters):\n",
    "          z = 0.0\n",
    "          #print(\"for (\",y,\",\",x,\",\",f,\")\")\n",
    "          for ky in range(min(self.cell_size, self.input_height - y*self.cell_size)):\n",
    "            for kx in range(min(self.cell_size, self.input_width - x*self.cell_size)):\n",
    "              #print(\"    adding (\",self.cell_size*y+ky,\",\",self.cell_size*x+kx,\",\",f,\")\")\n",
    "              z += self.inputs.value[self.cell_size*y+ky, self.cell_size*x+kx, f]\n",
    "                \n",
    "          self.value[y, x, f] = z / (self.cell_size * self.cell_size)\n",
    "          \n",
    "  def backward(self):\n",
    "    ## Complete this method by setting the partial with repect to the values of the inputs\n",
    "    ## self.inputs.dloss_dvalue, an `input_height x input_width x filters` tensor\n",
    "    ## This will use the partial with respect to the value of this layer\n",
    "    ## self.dloss_dvalue, a `height x width x filters` tensor\n",
    "    d_xsq = float(1)/((self.cell_size * self.cell_size)) \n",
    "\n",
    "    for y in range(self.input_height):\n",
    "      for x in range(self.input_width):\n",
    "        for f in range(self.input_filters):\n",
    "          curr_x = int(x/2)\n",
    "          curr_y = int(y/2)\n",
    "          self.inputs.dloss_dvalue[y, x, f] = self.dloss_dvalue[curr_y, curr_x, f] * d_xsq\n",
    "                \n",
    "  def gradient_step(self, step_size):\n",
    "    pass\n",
    "  \n",
    "# Double check that each op matches tensorflow\n",
    "print(\"\\nTesting AvgPool...\")\n",
    "op3 = OpAvgPool(2, inputs)\n",
    "tf_op3 = tf.nn.avg_pool(tf_inputs, [1, 2, 2, 1], [1,2,2,1], \"VALID\")\n",
    "cmp_ops(op3, tf_op3, tf_inputs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YTOQFqDmd1LU"
   },
   "source": [
    "## 3.1.4 Softmax Cross-entropy Loss (10 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "gfCoGsUDdhpo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Cross Entropy Loss...\n",
      "Forward pass:\n",
      "  Your Op shape: (1,)\n",
      "  TensorFlow Op shape: (1, 1)\n",
      "  Values equal: True\n",
      "Gradient wrt inputs:\n",
      "  Your Op shape: (1, 1, 3)\n",
      "  TensorFlow Op shape: (1, 1, 1, 3)\n",
      "  Values equal: True\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "class OpSoftmaxCrossEntropyLoss:\n",
    "  \"\"\"Cross-entropy loss.\"\"\"\n",
    "    \n",
    "  def __init__(self, logits, true_label):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "      logits: shape [1,1,num_classes]\n",
    "      true_label: scalar in range [0, num_classes-1]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Shape of the input feature map\n",
    "    self.num_classes = logits.value.shape[2]\n",
    "    self.inputs = logits\n",
    "    self.true_label = true_label\n",
    "    \n",
    "  def reset_values(self):\n",
    "    self.max_label = 0\n",
    "    self.value = np.zeros((1,))\n",
    "    self.softmax_prob = np.zeros((self.num_classes,))\n",
    "    \n",
    "  def forward(self):\n",
    "    # Reset value and gradient at start of forward pass\n",
    "    self.reset_values()\n",
    "    ## Complete this method by:\n",
    "    ## (1) setting self.value to the scalar value of the \n",
    "    ##     negative log probability of the true class under a Softmax distribution.\n",
    "    ##     Loss = -ln(exp(y_true) / sum_j (exp(y_j))), where y_j is the logits\n",
    "    ##     value for class j.\n",
    "    ## (2) setting self.softmax_prob to the vector representing the probability\n",
    "    ##     of each class according to the Softmax distribution\n",
    "    ##     softmax_prob[j] = exp(y_i) / sum_j (exp(y_j)), where y_j is the logits\n",
    "    ##     value for class j.\n",
    "    ## This will use\n",
    "    ## self.inputs.value, a `1 x 1 x num_classes` tensor containing the logits\n",
    "    sum_exp_logits = 0\n",
    "    \n",
    "    for i in range(self.num_classes):\n",
    "        sum_exp_logits += math.exp(self.inputs.value[0,0, i])\n",
    "    for i in range(self.num_classes):        \n",
    "        self.softmax_prob[i] = math.exp(self.inputs.value[0,0,i]) / sum_exp_logits\n",
    "    \n",
    "    self.value[0] = - math.log(math.exp(self.inputs.value[0, 0, self.true_label.value]) / sum_exp_logits)\n",
    "          \n",
    "  def backward(self):\n",
    "    # Loss = -ln(exp(y_true) / sum_j (exp(y_j)))\n",
    "    # dLoss/dYk = exp(y_k) / sum_j (exp(y_j))\n",
    "    # dLoss/dYtrue = exp(y_true) / sum_j (exp(y_j)) - 1\n",
    "    self.inputs.dloss_dvalue[0, 0, :] += self.softmax_prob\n",
    "    self.inputs.dloss_dvalue[0, 0, self.true_label.value] += -1\n",
    "                \n",
    "  def gradient_step(self, step_size):\n",
    "    pass\n",
    "  \n",
    "# Double check that each op matches tensorflow\n",
    "print(\"\\nTesting Cross Entropy Loss...\")\n",
    "pooled = OpAvgPool(10, inputs)\n",
    "pooled.forward()\n",
    "tf_pooled = tf.nn.avg_pool(tf_inputs, [1, 10, 10, 1], [1,10,10,1], \"VALID\")\n",
    "\n",
    "true_label = Variable()\n",
    "op4 = OpSoftmaxCrossEntropyLoss(pooled, true_label)\n",
    "tf_op4 = tf.nn.softmax_cross_entropy_with_logits_v2(logits=tf_pooled, \n",
    "                                                    labels=tf.one_hot(tf.constant(0), 3))\n",
    "cmp_ops(op4, tf_op4, tf_pooled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kup9p9q8eSXn"
   },
   "source": [
    "## 3.1.5 Run for a few iterations (10 pts)\n",
    "\n",
    "Here we assemble all of our operations into a full convolutional neural network.  We then run stochastic gradient descent on a small collection of ten images to ensure that the loss is decreasing.\n",
    "\n",
    "Run this cell to plot 100 iterations of training. **(5 pts)**\n",
    "\n",
    "Why is this plot jagged?  What is it about our architecture or training procedure that causes this, and how might adjusting these factors change the shape of this curve? **(5 pts)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "QE1qrTr1coAr",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "Iteration 0 Loss: [23.41012041]\n",
      "Iteration 1 Loss: [23.04136509]\n",
      "Iteration 2 Loss: [33.02728799]\n",
      "Iteration 3 Loss: [22.87526167]\n",
      "Iteration 4 Loss: [23.91612511]\n",
      "Iteration 5 Loss: [24.99470937]\n",
      "Iteration 6 Loss: [22.92684561]\n",
      "Iteration 7 Loss: [23.12011341]\n",
      "Iteration 8 Loss: [23.6434794]\n",
      "Iteration 9 Loss: [20.99400669]\n",
      "Iteration 10 Loss: [19.65962341]\n",
      "Iteration 11 Loss: [17.43971532]\n",
      "Iteration 12 Loss: [16.81324139]\n",
      "Iteration 13 Loss: [11.25986187]\n",
      "Iteration 14 Loss: [11.60630934]\n",
      "Iteration 15 Loss: [7.75956445]\n",
      "Iteration 16 Loss: [3.91766387]\n",
      "Iteration 17 Loss: [2.61136097]\n",
      "Iteration 18 Loss: [0.56996349]\n",
      "Iteration 19 Loss: [0.17073335]\n",
      "Iteration 20 Loss: [0.10324958]\n",
      "Iteration 21 Loss: [0.07379704]\n",
      "Iteration 22 Loss: [0.05912035]\n",
      "Iteration 23 Loss: [0.04928768]\n",
      "Iteration 24 Loss: [0.04206357]\n",
      "Iteration 25 Loss: [0.03675321]\n",
      "Iteration 26 Loss: [0.03248868]\n",
      "Iteration 27 Loss: [0.02912694]\n",
      "Iteration 28 Loss: [0.02635941]\n",
      "Iteration 29 Loss: [0.02407387]\n",
      "Iteration 30 Loss: [0.02211561]\n",
      "Iteration 31 Loss: [0.02045481]\n",
      "Iteration 32 Loss: [0.01902443]\n",
      "Iteration 33 Loss: [0.01776665]\n",
      "Iteration 34 Loss: [0.01665903]\n",
      "Iteration 35 Loss: [0.01567942]\n",
      "Iteration 36 Loss: [0.01480166]\n",
      "Iteration 37 Loss: [0.01400921]\n",
      "Iteration 38 Loss: [0.01328856]\n",
      "Iteration 39 Loss: [0.01263496]\n",
      "Iteration 40 Loss: [0.012043]\n",
      "Iteration 41 Loss: [0.01149989]\n",
      "Iteration 42 Loss: [0.01100061]\n",
      "Iteration 43 Loss: [0.01054451]\n",
      "Iteration 44 Loss: [0.01012262]\n",
      "Iteration 45 Loss: [0.00973088]\n",
      "Iteration 46 Loss: [0.00936687]\n",
      "Iteration 47 Loss: [0.00902727]\n",
      "Iteration 48 Loss: [0.00871002]\n",
      "Iteration 49 Loss: [0.00841282]\n",
      "Iteration 50 Loss: [0.00813405]\n",
      "Iteration 51 Loss: [0.00787185]\n",
      "Iteration 52 Loss: [0.00762462]\n",
      "Iteration 53 Loss: [0.00739158]\n",
      "Iteration 54 Loss: [0.00717145]\n",
      "Iteration 55 Loss: [0.00696317]\n",
      "Iteration 56 Loss: [0.00676585]\n",
      "Iteration 57 Loss: [0.00657882]\n",
      "Iteration 58 Loss: [0.0064013]\n",
      "Iteration 59 Loss: [0.00623373]\n",
      "Iteration 60 Loss: [0.00607424]\n",
      "Iteration 61 Loss: [0.00592191]\n",
      "Iteration 62 Loss: [0.00577619]\n",
      "Iteration 63 Loss: [0.00563655]\n",
      "Iteration 64 Loss: [0.0055016]\n",
      "Iteration 65 Loss: [0.00537266]\n",
      "Iteration 66 Loss: [0.00524915]\n",
      "Iteration 67 Loss: [0.00513098]\n",
      "Iteration 68 Loss: [0.00501779]\n",
      "Iteration 69 Loss: [0.00490931]\n",
      "Iteration 70 Loss: [0.00480489]\n",
      "Iteration 71 Loss: [0.00470461]\n",
      "Iteration 72 Loss: [0.00460806]\n",
      "Iteration 73 Loss: [0.00451522]\n",
      "Iteration 74 Loss: [0.00442572]\n",
      "Iteration 75 Loss: [0.00433952]\n",
      "Iteration 76 Loss: [0.00425634]\n",
      "Iteration 77 Loss: [0.00417612]\n",
      "Iteration 78 Loss: [0.00409893]\n",
      "Iteration 79 Loss: [0.00402436]\n",
      "Iteration 80 Loss: [0.00395226]\n",
      "Iteration 81 Loss: [0.00388254]\n",
      "Iteration 82 Loss: [0.00381505]\n",
      "Iteration 83 Loss: [0.00374958]\n",
      "Iteration 84 Loss: [0.00368617]\n",
      "Iteration 85 Loss: [0.00362475]\n",
      "Iteration 86 Loss: [0.00356524]\n",
      "Iteration 87 Loss: [0.00350752]\n",
      "Iteration 88 Loss: [0.00345152]\n",
      "Iteration 89 Loss: [0.00339719]\n",
      "Iteration 90 Loss: [0.00334455]\n",
      "Iteration 91 Loss: [0.00329337]\n",
      "Iteration 92 Loss: [0.00324365]\n",
      "Iteration 93 Loss: [0.00319529]\n",
      "Iteration 94 Loss: [0.00314828]\n",
      "Iteration 95 Loss: [0.00310284]\n",
      "Iteration 96 Loss: [0.00305856]\n",
      "Iteration 97 Loss: [0.00301541]\n",
      "Iteration 98 Loss: [0.0029735]\n",
      "Iteration 99 Loss: [0.0029327]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x520bb70>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# Construct a mini network for MNIST\n",
    "inputs = Variable()\n",
    "true_label = Variable()\n",
    "inputs.value = np.random.normal(size=(28, 28, 1))\n",
    "inputs.dloss_dvalue = np.random.normal(size=(28, 28, 1))\n",
    "\n",
    "op1 = OpConv2D(16, 5, inputs) # Output is 28-5+1=24\n",
    "op2 = OpAvgPool(2, op1)      # Output is 24/2=12\n",
    "op3 = OpRelu(op2)\n",
    "\n",
    "op4 = OpConv2D(16, 5, op3) # Output is 12-5+1=8\n",
    "op5 = OpAvgPool(2, op4)      # Output is 8/2=4\n",
    "op6 = OpRelu(op5)\n",
    "\n",
    "op7 = OpConv2D(10, 3, op6) # Output is 4-3+1=2\n",
    "op8 = OpAvgPool(2, op7)      # Output is 2/2=1\n",
    "\n",
    "op9 = OpSoftmaxCrossEntropyLoss(op8, true_label)\n",
    "ops_list = [op1,op2,op3,op4,op5,op6,op7,op8,op9]\n",
    "\n",
    "# Run for a few iterations, make sure loss is going down\n",
    "learning_rate = 0.2\n",
    "inputs.value = np.random.normal(size=(28, 28, 1))\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=False)\n",
    "\n",
    "num_its = 100\n",
    "batch_size = 10\n",
    "batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "\n",
    "loss_list = []\n",
    "\n",
    "for it in range(num_its):\n",
    "  loss_of_batch = 0.0\n",
    "  \n",
    "  for im in range(batch_size):\n",
    "    inputs.value = np.reshape(batch_x[im], (28,28,1))\n",
    "    true_label.value = batch_y[im]\n",
    "  \n",
    "    for op in ops_list:\n",
    "      op.forward()\n",
    "\n",
    "    loss_of_batch += ops_list[-1].value\n",
    "    \n",
    "    for op in reversed(ops_list):\n",
    "      op.backward()\n",
    "      op.gradient_step(learning_rate)\n",
    "  \n",
    "  loss_list.append(loss_of_batch)\n",
    "  \n",
    "  print(\"Iteration \" + str(it) + \" Loss: \"+str(loss_of_batch))\n",
    "  \n",
    "  \n",
    "plt.plot(range(num_its), loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KWyWnrg7nLFC"
   },
   "source": [
    "## 3.1.6 Extra credit (5 points)\n",
    "\n",
    "Extend the functionality of one of these operations (e.g. add stride, dilation, or padding to the 2D Convolution) or implement a new one (e.g. fully-connected layer).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DQBxDYsJidXP"
   },
   "source": [
    "# 3.2 Training an image classifier (40 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_opHX46kic3G"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the path specified.\n"
     ]
    }
   ],
   "source": [
    "#@title (Hidden utility code: RUN ME FIRST) { display-mode: \"form\" }\n",
    "!git clone https://github.com/tensorflow/models.git /content >/dev/null\n",
    "import sys\n",
    "import math\n",
    "sys.path.append('C:\\\\content\\\\tutorials\\\\image\\\\cifar10')\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "try:\n",
    "  tf.app.flags.FLAGS.f\n",
    "except Exception:\n",
    "  tf.app.flags.DEFINE_string('f', '', \"\"\"Placeholder.\"\"\")\n",
    "import cifar10\n",
    "tf.app.flags.FLAGS.batch_size = 100\n",
    "#from tensorflow.examples.models.tutorials.image.cifar10 import cifar10\n",
    "\n",
    "def plot_filters(filters, xlabel=None, ylabel=None):\n",
    "  print(filters.shape)\n",
    "  # filters: height x width x channels x num_filters\n",
    "  num_filters = filters.shape[3]\n",
    "  filter_height = filters.shape[0]\n",
    "  filter_width = filters.shape[1]\n",
    "  filter_channels = filters.shape[2]\n",
    "  spacing = 1\n",
    "  rows = int(math.ceil(math.sqrt(num_filters)))\n",
    "  cols = int(math.ceil(math.sqrt(num_filters)))\n",
    "  plot = np.zeros((rows*(filter_height+spacing), cols*(filter_width+spacing), min(filter_channels, 3) ))\n",
    "  \n",
    "  min_value = np.min(filters)\n",
    "  max_value = np.max(filters)\n",
    "  filters = (filters - min_value) / (max_value - min_value)\n",
    "  \n",
    "  for f in range(num_filters):\n",
    "    r = int(f/cols)\n",
    "    c = f - r*cols\n",
    "    plot[r*(filter_height+spacing):r*(filter_height+spacing)+filter_height,\n",
    "        c*(filter_width+spacing):c*(filter_width+spacing)+filter_width,:] = filters[:,:,0:min(filter_channels, 3),f]\n",
    "  \n",
    "  plt.grid(False)\n",
    "  plt.imshow(np.squeeze(plot))\n",
    "  if xlabel is not None:\n",
    "    plt.xlabel(xlabel)\n",
    "  if ylabel is not None:\n",
    "    plt.ylabel(ylabel)\n",
    "  plt.show()\n",
    "\n",
    "cifar10.maybe_download_and_extract()\n",
    "images, labels = cifar10.inputs(False)\n",
    "test_images, test_labels = cifar10.inputs(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QRA3pZgr3Z2W"
   },
   "source": [
    "## 3.2.1 Early stopping (15 points)\n",
    "\n",
    "We have specified a very simple convolutional neural network to classify images from the Cifar-10 dataset.  We then provide a training loop to optimize the weights of the network.  Your task is to add Early Stopping (ES) to this training loop.  Validation accuracy should be measured periodically, and training should stop if the validation accuracy does not reach a new absolute maximum after some number of measurements (this is called the \"patience\"). After training, we then measure the test accuracy.  Before implementing ES, run the following cell to see a plot of the training loss and validation accuracy.  Report the test accuracy you have found with ES.\n",
    "\n",
    "## 3.2.2 Tuning hyperparameters (25 points)\n",
    "\n",
    "The hyperparameters we have chosen are not necessarily optimal.  Pick two factors to search over (e.g. number of layers, filters per layer, learning rate, convolutional kernel size, etc.).  Then write a procedure that uses grid search to find the combination of these hyperparameters that yields the highest validation accuracy.  Finally, report the test accuracy achieved by this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "sW5cHzOB7gsX",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training... 2018-05-19 18:20:19.066374\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
      "Testing... 2018-05-19 18:26:25.767278\n",
      "Test accuracy: 25.0%%\n",
      "best accuracy now 25.0  with  32  filter size,  0.001  learning rate \n",
      "Training... 2018-05-19 18:26:27.709687\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
      "Testing... 2018-05-19 18:30:59.684966\n",
      "Test accuracy: 20.999999344348907%%\n",
      "Training... 2018-05-19 18:31:00.982773\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
      "Testing... 2018-05-19 18:38:57.356155\n",
      "Test accuracy: 33.000001311302185%%\n",
      "best accuracy now 33.000001311302185  with  96  filter size,  0.001  learning rate \n",
      "Training... 2018-05-19 18:39:00.262963\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
      "Testing... 2018-05-19 19:02:20.330376\n",
      "Test accuracy: 41.999998688697815%%\n",
      "best accuracy now 41.999998688697815  with  128  filter size,  0.001  learning rate \n",
      "Training... 2018-05-19 19:02:24.362593\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
      "Testing... 2018-05-19 19:30:22.522267\n",
      "Test accuracy: 46.99999988079071%%\n",
      "best accuracy now 46.99999988079071  with  32  filter size,  0.005  learning rate \n",
      "Training... 2018-05-19 19:30:27.176080\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
      "Testing... 2018-05-19 20:04:21.588244\n",
      "Test accuracy: 49.000000953674316%%\n",
      "best accuracy now 49.000000953674316  with  64  filter size,  0.005  learning rate \n",
      "Training... 2018-05-19 20:04:27.807060\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
      "Testing... 2018-05-19 20:25:00.615935\n",
      "Test accuracy: 34.00000035762787%%\n",
      "Training... 2018-05-19 20:25:04.960549\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
      "Testing... 2018-05-19 21:01:10.333185\n",
      "Test accuracy: 46.00000083446503%%\n",
      "Training... 2018-05-19 21:01:14.982398\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
      "Testing... 2018-05-19 21:16:12.152907\n",
      "Test accuracy: 31.00000023841858%%\n",
      "Training... 2018-05-19 21:16:17.604921\n",
      "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
      "Testing... 2018-05-19 22:21:41.333585\n",
      "Test accuracy: 52.99999713897705%%\n",
      "best accuracy now 52.99999713897705  with  64  filter size,  0.01  learning rate \n",
      "Training... 2018-05-19 22:21:50.947514\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-b5137dae6fa8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m         \u001b[0mloss_cnn_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcross_entropy_cnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_step_cnn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Thomas Weidmaier\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Thomas Weidmaier\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Thomas Weidmaier\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Thomas Weidmaier\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Thomas Weidmaier\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1303\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1305\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m   1307\u001b[0m           options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "\u001b[1;32mD:\\Users\\Thomas Weidmaier\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1338\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1340\u001b[1;33m         \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1341\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def layer_cnn(image, layer_cnt, filter_cnt, kernel_cnt):\n",
    "  #Validate there is at least one layer to generate\n",
    "  if(layer_cnt < 1):\n",
    "    print(\"Invalid layer count\")\n",
    "  \n",
    "  print(\"input shape:\",image.shape)\n",
    "  #Initialize first layer based off image\n",
    "  curr_cnn_layer = tf.layers.conv2d(image, filter_cnt, kernel_cnt, strides=(2,2), activation=tf.nn.relu)\n",
    "  print(\"shape:\", curr_cnn_layer.shape)\n",
    "  #Loop through and create subsequent layers based off the previous one\n",
    "  for i in range (1, layer_cnt):\n",
    "    curr_cnn_layer = tf.layers.conv2d(curr_cnn_layer, filter_cnt * (i/2), kernel_cnt, activation=tf.nn.relu)\n",
    "    print(\"shape:\", curr_cnn_layer.shape)\n",
    "  return tf.reduce_sum(tf.reduce_sum(curr_cnn_layer, axis=1), axis=1)\n",
    "    \n",
    "learning_rates = [ .001, .005, .01, .02, .05, .1, .2, .5, .75, 1]\n",
    "filters = [32, 64, 96, 128]\n",
    "sess = tf.Session()\n",
    "with sess.as_default():\n",
    "  test_acc = -1\n",
    "  for curr_lr in learning_rates:  \n",
    "    for f in filters:\n",
    "      tf.train.start_queue_runners()\n",
    "      im_width = 24\n",
    "\n",
    "      # Define placeholders for image and label\n",
    "      y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "      x = tf.placeholder(tf.float32, [None, im_width, im_width, 3])\n",
    "\n",
    "      # Define a convolutional neural network (CNN)\n",
    "      cnnL1 = tf.layers.conv2d(x, f, 5, strides=(2,2), activation=tf.nn.relu)\n",
    "      cnnL2 = tf.layers.conv2d(cnnL1, f, 5, activation=tf.nn.relu)\n",
    "      cnnL3 = tf.layers.conv2d(cnnL2, f, 5, activation=tf.nn.relu)\n",
    "      cnn = tf.reduce_sum(tf.reduce_sum(cnnL3, axis=1), axis=1)\n",
    "      #cnn = layer_cnn(x, 12, curr_filter_cnt, 3)\n",
    "      cnn = tf.contrib.layers.flatten(cnn)\n",
    "      y_cnn = tf.layers.dense(cnn, 10)\n",
    "\n",
    "      cross_entropy_cnn = tf.reduce_mean(\n",
    "          tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_, logits=y_cnn))\n",
    "      train_step_cnn = tf.train.GradientDescentOptimizer(curr_lr).minimize(cross_entropy_cnn)\n",
    "\n",
    "      correct_prediction_cnn = tf.equal(tf.argmax(y_cnn, 1), tf.argmax(y_, 1))\n",
    "      accuracy_cnn = tf.reduce_mean(tf.cast(correct_prediction_cnn, tf.float32))\n",
    "\n",
    "      tf.global_variables_initializer().run(session=sess)\n",
    "\n",
    "      #Thweid: Additional values added for Early Stopping \n",
    "      saver = tf.train.Saver()\n",
    "      best_sess_path = \"/tmp/model.ckpt\"\n",
    "      best_total_path = \"/tmp/best-model.ckpt\"\n",
    "      curr_max_accuracy = -1\n",
    "      curr_patience = 0\n",
    "      max_patience = 25\n",
    "      validation_increment = 15\n",
    "      quit_flag = False\n",
    "\n",
    "      # Train\n",
    "      print('Training... '+str(datetime.now()))\n",
    "      valid_batch_xs, valid_batch_ys = sess.run([test_images, tf.one_hot(test_labels, 10)])\n",
    "      train_losses = []\n",
    "      test_accuracies = []\n",
    "      valid_its = []\n",
    "      valid_accuracies = []\n",
    "      num_its = 2000\n",
    "      for it in range(num_its):\n",
    "        if (it+1) % validation_increment == 0:\n",
    "          #print('Iteration %d/%d ...' % (it, num_its))\n",
    "\n",
    "          # Validation accuracy\n",
    "          valid_acc_cnn = sess.run(accuracy_cnn, feed_dict={x: valid_batch_xs, y_: valid_batch_ys})\n",
    "          valid_accuracies.append(valid_acc_cnn)\n",
    "          valid_its.append(it)\n",
    "\n",
    "          #Thweid:Increase patience\n",
    "          #       Check to see if a new max validity is found, reseting the max patience if so\n",
    "          #       Verify patience hasn't been exhausted, exiting if so\n",
    "          curr_patience += 1\n",
    "          if (valid_acc_cnn > curr_max_accuracy):\n",
    "            #print(\"best accuracy at\", it,\"-\",valid_acc_cnn)\n",
    "            saver.save(sess, best_sess_path)\n",
    "            curr_max_accuracy = valid_acc_cnn\n",
    "            curr_patience = 0\n",
    "          if(curr_patience > max_patience):\n",
    "            quit_flag = True \n",
    "\n",
    "\n",
    "        batch_xs, batch_ys = sess.run([images, tf.one_hot(labels, 10)])\n",
    "        loss_cnn_out, _ = sess.run([cross_entropy_cnn, train_step_cnn], feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "        train_losses.append(loss_cnn_out)\n",
    "\n",
    "        #Thweid: If flag set to quit, then stop going through validation set\n",
    "        if(quit_flag):\n",
    "          break\n",
    "\n",
    "      #Restore saved session\n",
    "      saver.restore(sess, best_sess_path)\n",
    "      best_training_acc_cnn = sess.run(accuracy_cnn, feed_dict={x: valid_batch_xs, y_: valid_batch_ys})\n",
    "\n",
    "      print('Testing... '+str(datetime.now()))\n",
    "      # # Test trained model\n",
    "      test_batch_xs, test_batch_ys = sess.run([test_images, tf.one_hot(test_labels, 10)])\n",
    "\n",
    "      true_label = tf.argmax(y_, 1)\n",
    "      cnn_label = tf.argmax(y_cnn, 1)\n",
    "      acc_cnn_out, true_label_out, cnn_label_out = sess.run([accuracy_cnn, true_label, cnn_label], feed_dict={x: test_batch_xs,\n",
    "                                          y_: test_batch_ys})\n",
    "\n",
    "      # Plot train loss and validation accuracy\n",
    "      #plt.plot(range(it+1), train_losses)\n",
    "      #plt.ylabel('Training loss')\n",
    "      #plt.xlabel('Iteration')\n",
    "      #plt.show()\n",
    "      #plt.plot(valid_its, valid_accuracies)\n",
    "      #plt.ylabel('Validation accuracy')\n",
    "      #plt.xlabel('Iteration')\n",
    "      #plt.show()\n",
    "\n",
    "      print('Test accuracy: ' + str(acc_cnn_out*100)+ '%%')\n",
    "    \n",
    "      if(acc_cnn_out > test_acc):\n",
    "        print(\"best accuracy now\",str(acc_cnn_out*100),\" with \",f,\" filter size, \",curr_lr,\" learning rate \")\n",
    "        test_acc = acc_cnn_out\n",
    "        saver.save(sess, best_total_path)\n",
    "\n",
    "\n",
    "saver.restore(sess, best_total_path)\n",
    "test_batch_xs, test_batch_ys = sess.run([test_images, tf.one_hot(test_labels, 10)])\n",
    "\n",
    "true_label = tf.argmax(y_, 1)\n",
    "cnn_label = tf.argmax(y_cnn, 1)\n",
    "acc_cnn_out, true_label_out, cnn_label_out = sess.run([accuracy_cnn, true_label, cnn_label], feed_dict={x: test_batch_xs,\n",
    "                                          y_: test_batch_ys})        \n",
    "        \n",
    "# Plot train loss and validation accuracy\n",
    "plt.plot(range(it+1), train_losses)\n",
    "plt.ylabel('Training loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.show()\n",
    "plt.plot(valid_its, valid_accuracies)\n",
    "plt.ylabel('Validation accuracy')\n",
    "plt.xlabel('Iteration')\n",
    "plt.show()\n",
    "\n",
    "print('Final Test accuracy: ' + str(acc_cnn_out*100)+ '%%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PoGc-6q5bS9M"
   },
   "source": [
    "If you are curious what the weights, activations, or confused images look like, we visualize them below.  Feel free to modify this code to inspect other aspects of your trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "9z2FGsc9CSdX"
   },
   "source": [
    "with sess.as_default():\n",
    "  # Show weights from the first layer\n",
    "  print('Weights from the first layer')\n",
    "  with tf.variable_scope(\"conv2d_1\", reuse=True):\n",
    "    weights = tf.get_variable('kernel')\n",
    "  plot_filters(weights.eval())\n",
    "\n",
    "  # Show activations from the first feature map\n",
    "  print('Activations from the first feature map.')\n",
    "  fmap = cnnL1.eval(feed_dict={x: test_batch_xs, y_: test_batch_ys})\n",
    "  plot_filters(np.transpose(fmap[0:1,...], (1,2,0,3)))\n",
    "\n",
    "  # Show images in a confusion matrix\n",
    "  confusion = np.zeros((24,24,3,100))\n",
    "  for b in range(true_label_out.shape[0]):\n",
    "    confusion[:,:,:,true_label_out[b]*10 + cnn_label_out[b]] = test_batch_xs[b]\n",
    "\n",
    "  plot_filters(confusion, ylabel='True label', xlabel='Guessed label')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Copy of Assignment3.ipynb",
   "provenance": [
    {
     "file_id": "0B-TLIIJqcZpNV3pjWEthUXhPMnc",
     "timestamp": 1523060994854
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
