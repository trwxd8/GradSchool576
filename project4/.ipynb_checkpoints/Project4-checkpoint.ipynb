{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xlDSCPelBKup"
   },
   "source": [
    "# Project 4: Stereo Matching with ML\n",
    "\n",
    "This is Project 4 for [UW CSE P576 Computer Vision](https://courses.cs.washington.edu/courses/csep576/18sp/).\n",
    "\n",
    "**Getting Started:** Download the [source ipynb](https://courses.cs.washington.edu/courses/csep576/18sp/projects/project4/project4.zip) for this notebook and use File->Upload Notebook in Colab. \n",
    "\n",
    "**This project:** In this project you will build a model for stereo matching. First, you'll implement and test standard block matching as a Tensorflow graph. Next, you will add a convolutional net to the output of your block matcher, and train the network using images from the KITTI dataset.\n",
    "\n",
    "**What to turn in:** Turn in a pdf of your completed ipynb notebook as well as the source .ipynb. Clearly describe any enhancements or experiments you tried in your ipynb notebook.\n",
    "\n",
    "`version 051618`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wxBmyFTTz2CQ"
   },
   "source": [
    "### Copyright 2018 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "\n",
    "This is not an official Google product.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "8pq04vKr0cz9"
   },
   "outputs": [],
   "source": [
    "#@title \n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i7w2_mZe0yTl"
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "YPInjbR3aWca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/tensorflow/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import PIL.Image as pil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16.0, 10.0)\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "def image_open(filename):\n",
    "  \"\"\"\n",
    "  Returns a numpy float image with values in the range (0,1)\n",
    "  \"\"\"\n",
    "  pil_im = pil.open(filename)\n",
    "  im_np = np.array(pil_im).astype(np.float32)\n",
    "  im_np /= 255.0\n",
    "  return im_np\n",
    "\n",
    "def grey_to_rgb(img):\n",
    "  \"\"\"\n",
    "  Convert greyscale to rgb image\n",
    "  \"\"\"\n",
    "  if (len(img.shape)==2):\n",
    "    img = np.expand_dims(img, 2)\n",
    "\n",
    "  img3 = np.repeat(img, 3, 2)\n",
    "  return img3\n",
    "\n",
    "def normalise_01(im):\n",
    "  \"\"\"\n",
    "  Normalise image to the range (0,1)\n",
    "  \"\"\"\n",
    "  mx = im.max()\n",
    "  mn = im.min()\n",
    "  den = mx-mn\n",
    "  small_val = 1e-9\n",
    "  if (den < small_val):\n",
    "    print('image normalise_01 -- divisor is very small')\n",
    "    den = small_val\n",
    "  return (im-mn)/den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "RrYC0PTbdr--",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: wget: command not found\r\n"
     ]
    }
   ],
   "source": [
    "#@title\n",
    "# Download KITTI data\n",
    "!wget -nc https://courses.cs.washington.edu/courses/csep576/18sp/projects/project4/kitti_stereo2012.zip && unzip -n kitti_stereo2012.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sy7IoTxtC6H6"
   },
   "source": [
    "## Visualising KITTI data [15%]\n",
    "\n",
    "We'll start by reading in some images to perform block matching on. The code below displays a random left image, and the average of left and right images. You should see that the pixel difference (disparity) for nearby objects is larger for foreground objects than for distant ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "9FfJBQIUfFY1"
   },
   "outputs": [],
   "source": [
    "# Visualise left,right and disparity images\n",
    "num_data=194\n",
    "im_id=np.random.randint(num_data)\n",
    "\n",
    "left_im=tf.image.decode_image(tf.read_file('kitti_stereo2012/training/image_0/'+str(im_id).zfill(6)+'_10.png'))\n",
    "right_im=tf.image.decode_image(tf.read_file('kitti_stereo2012/training/image_1/'+str(im_id).zfill(6)+'_10.png'))\n",
    "disp_im=tf.image.decode_image(tf.read_file('kitti_stereo2012/training/disp_occ/'+str(im_id).zfill(6)+'_10.png'))\n",
    "\n",
    "left_im=tf.to_float(left_im[:,:,0])/255.0\n",
    "right_im=tf.to_float(right_im[:,:,0])/255.0\n",
    "disp_im=tf.to_float(disp_im[:,:,0])\n",
    "\n",
    "sess=tf.Session()\n",
    "left_im_np=sess.run(left_im)\n",
    "right_im_np=sess.run(right_im)\n",
    "sess.close()\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.imshow(grey_to_rgb(left_im_np))\n",
    "plt.axis('off')\n",
    "plt.subplot(2,1,2)\n",
    "plt.imshow(grey_to_rgb(0.5*left_im_np+0.5*right_im_np))\n",
    "plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dydei36V1Qzt"
   },
   "source": [
    "Complete the code block below to visualise the ground truth disparity data. What is the approximate disparity range? Hint: try using `np.histogram` with a set of images. Which regions of the image have valid disparity values? Try a averaging over a several images to visualise the spatial range of the depth data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "k58G_rsRjEXK"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "********************************************************\n",
    "*** TODO: write code to visualise disparity ground truth\n",
    "********************************************************\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "********************************************************\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hecmIHSS6ygI"
   },
   "source": [
    "## Block Matching in Tensorflow [25%]\n",
    "\n",
    "You will now write Tensorflow code to perform block matching. Edit the function `compute_cost_volume` below to compute a 3D tensor such that `cost_volume[row,col,disparity]` is the SSD between a patch of size `block_match_size` from the left image, and a patch shifted by `disparity` pixels in the right image. Hint: try the Tensorflow functions `tf.extract_image_patches` and `tf.manip.roll`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hCw13eXDYdsZ"
   },
   "outputs": [],
   "source": [
    "def compute_cost_volume(left_im, right_im,block_match_size,disparity_range):\n",
    "  \n",
    "  # FORNOW: random cost volume  \n",
    "  cost_volume=tf.random_normal([370,1226,disparity_range])\n",
    "  \n",
    "  \"\"\"\n",
    "  **************************************************************\n",
    "  *** TODO: write code to compute the block matching cost volume\n",
    "  **************************************************************\n",
    "\n",
    "  Inputs: left_im=left image (H, W)\n",
    "          right_im=right image (H, W)\n",
    "          block_match_size=size of square for patch matching\n",
    "          disparity_range=range of disparities to compute\n",
    "\n",
    "  Outputs: cost_volume=output cost volume (H, W, disparity_range)\n",
    "  \"\"\"\n",
    "  \n",
    "  \n",
    "  \"\"\"\n",
    "  **************************************************************\n",
    "  \"\"\"\n",
    "  \n",
    "  return cost_volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DS2_B5r0Lj1y"
   },
   "source": [
    "The code below calls `compute_cost_volume` and finds the min cost at each pixel to estimate disparity. Check the output looks sensible. What is the effect of `block_match_size` and `disparity_range` on the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "aGtfZGEcLf5M"
   },
   "outputs": [],
   "source": [
    "cost_vol=compute_cost_volume(left_im,right_im,block_match_size=3,disparity_range=80)\n",
    "block_est=tf.argmin(cost_vol,axis=2)\n",
    "block_est=tf.to_float(block_est)\n",
    "\n",
    "sess=tf.Session()\n",
    "cost_vol_np=sess.run(cost_vol)\n",
    "block_est_np=sess.run(block_est)\n",
    "sess.close()\n",
    "\n",
    "plt.subplot(1,1,1)\n",
    "plt.imshow(grey_to_rgb(normalise_01(block_est_np)))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XPOGHzG_Yq1u"
   },
   "source": [
    "The code below uses the `compute_cost_volume` function in a data provider that creates batches by extracting patches from the training data. In subsequent experiments, you can adjust block matching settings using the parameters in the `StereoDataProvider` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "9CabkaF1d-76"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "class StereoDataProvider:\n",
    "  \"\"\"\n",
    "  Provide data for stereo images\n",
    "  \"\"\"\n",
    "  def __init__(self):\n",
    "    self.params={}\n",
    "    self.params['patch_size']=64\n",
    "    self.params['num_patches_per_image']=100\n",
    "    self.params['block_match_size']=3\n",
    "    self.params['disparity_range']=80\n",
    "    self.params['ignore_top_rows']=100\n",
    "    self.params['batch_size']=5\n",
    "    self.params['shuffle_buffer_size']=1000\n",
    "    self.params['prefetch_buffer_size']=2\n",
    "    self.params['num_epochs']=10\n",
    "    self.params['height']=370\n",
    "    self.params['width']=1226\n",
    "\n",
    "    self.input_filenames=[]\n",
    "    self.target_filenames=[]\n",
    "\n",
    "  def get_batch(self):\n",
    "    # get a batch of patch data\n",
    "    dataset=tf.data.Dataset.from_tensor_slices((self.input_filenames,self.target_filenames))\n",
    "\n",
    "    dataset=dataset.repeat(self.params['num_epochs'])\n",
    "    dataset=dataset.map(self.read_images)\n",
    "    dataset=dataset.map(self.preprocess_images)\n",
    "    dataset=dataset.map(self.get_patches)\n",
    "    dataset=dataset.apply(tf.contrib.data.unbatch())\n",
    "    dataset=dataset.shuffle(buffer_size=self.params['shuffle_buffer_size'])\n",
    "    dataset=dataset.batch(self.params['batch_size'])\n",
    "    dataset=dataset.prefetch(self.params['prefetch_buffer_size'])\n",
    "\n",
    "    iterator=dataset.make_one_shot_iterator()\n",
    "    dataset_element=iterator.get_next()\n",
    "\n",
    "    return dataset_element\n",
    "\n",
    "  def get_preprocessed_images(self):\n",
    "    # get preprocessed images for inference\n",
    "    dataset=tf.data.Dataset.from_tensor_slices((self.input_filenames,self.target_filenames))\n",
    "\n",
    "    dataset=dataset.map(self.read_images)\n",
    "    dataset=dataset.map(self.preprocess_images)\n",
    "    dataset=dataset.batch(1)\n",
    "    dataset=dataset.prefetch(1)\n",
    "\n",
    "    iterator=dataset.make_one_shot_iterator()\n",
    "    dataset_element=iterator.get_next()\n",
    "\n",
    "    return dataset_element\n",
    "\n",
    "  def read_images(self,input_filenames,target_filename):\n",
    "\n",
    "    left_im=tf.image.decode_image(tf.read_file(input_filenames[0]))\n",
    "    right_im=tf.image.decode_image(tf.read_file(input_filenames[1]))\n",
    "    disp_im=tf.image.decode_image(tf.read_file(target_filename))\n",
    "\n",
    "    height=self.params['height']\n",
    "    width=self.params['width']\n",
    "\n",
    "    left_im=left_im[0:height,0:width,0]\n",
    "    right_im=right_im[0:height,0:width,0]\n",
    "    disp_im=disp_im[0:height,0:width,0]\n",
    "\n",
    "    # set shape explicitly (ambiguous due to image read)\n",
    "    left_im.set_shape((height,width))\n",
    "    right_im.set_shape((height,width))\n",
    "    disp_im.set_shape((height,width))\n",
    "\n",
    "    input_data=tf.to_float(tf.stack((left_im,right_im),2))/255.0 # images in range 0-1\n",
    "    target_disp=tf.to_float(tf.expand_dims(disp_im,2)) # disparity in pixels\n",
    "\n",
    "    return (input_data,target_disp)\n",
    "\n",
    "  def preprocess_images(self,input_data,target_disp):\n",
    "    # preprocess images to help depth learning\n",
    "    block_match_size=self.params['block_match_size']\n",
    "    disparity_range=self.params['disparity_range']\n",
    "\n",
    "    left_im=input_data[:,:,0]\n",
    "    right_im=input_data[:,:,1]\n",
    "\n",
    "    cost_volume=compute_cost_volume(left_im,right_im,block_match_size,disparity_range)\n",
    "    \n",
    "    input_data=cost_volume\n",
    "    #input_data=tf.concat((cost_volume,input_data),axis=2) \n",
    "      \n",
    "    return(input_data,target_disp)\n",
    "\n",
    "  def get_patches(self,input_data,target_disp):\n",
    "    # Extract patches from the input and targets\n",
    "    num_patches=self.params['num_patches_per_image']\n",
    "    patch_size=self.params['patch_size']\n",
    "\n",
    "    joined=tf.concat((input_data,target_disp),2)\n",
    "    joined_bands=joined.get_shape()[2] # static shape, inferred from graph\n",
    "    patch_list=[]\n",
    "\n",
    "    # don't select patches in first disparity range pixels\n",
    "    # or top rows of pixels where there is no disparity data\n",
    "    joined=joined[self.params['ignore_top_rows']:-1,self.params['disparity_range']:-1,:]\n",
    "\n",
    "    for _ in range(num_patches):\n",
    "      patch = tf.random_crop(joined,[patch_size,patch_size,joined_bands])\n",
    "      patch_list.append(patch)\n",
    "\n",
    "    patches=tf.stack(patch_list)\n",
    "    input_patches=patches[:,:,:,0:-1]\n",
    "    target_patches=patches[:,:,:,-1]\n",
    "    target_patches=tf.expand_dims(target_patches,3)\n",
    "\n",
    "    return (input_patches,target_patches)\n",
    "  \n",
    "  \n",
    "# The following function returns a stereo data provider for KITTI dataset\n",
    "def get_kitti_2012_dataset(image_id, data_dir):\n",
    "  # return kitti 2012 dataset corresponding to image_ids\n",
    "  input_filenames=[]\n",
    "  target_filenames=[]\n",
    "  for i in image_id:\n",
    "    left_filename=data_dir+'/image_0/'+str(i).zfill(6)+'_10.png'\n",
    "    right_filename=data_dir+'/image_1/'+str(i).zfill(6)+'_10.png'\n",
    "    disp_filename=data_dir+'/disp_occ/'+str(i).zfill(6)+'_10.png'\n",
    "    input_filenames.append((left_filename,right_filename))\n",
    "    target_filenames.append(disp_filename)\n",
    "\n",
    "  data_prov=StereoDataProvider()\n",
    "  data_prov.input_filenames=input_filenames\n",
    "  data_prov.target_filenames=target_filenames\n",
    "  return data_prov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-cv_UBx7Xvh3"
   },
   "source": [
    "## Launch Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xdUj8T2h9xcd"
   },
   "source": [
    "We will now launch a Tensorboard so that we can monitor the progress of training. The code below provides a function `launch_tensorboard` that allows us to access tensorbaord form the colab VM (this is from https://github.com/mixuala/colab_utils). Run this code and check that you can launch and connect to a Tensorboard (there will be nothing there yet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "yd08f1bo7ymE"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "# Copyright 2018 Michael Lin. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\"\"\"Contains code for adding common services to non-persistent `colaboratory` VM sessions\n",
    "  \n",
    "  When training on `colaboratory` VMs it it often useful to monitor the session via \n",
    "  `tensorboard`. This script helps you launches tensorboard on the `colaboratory` VM and \n",
    "  uses `ngrok` to create a secure introspective tunnel to access tensorboard via public URL.\n",
    "\n",
    "  see: https://stackoverflow.com/questions/47818822/can-i-use-tensorboard-with-google-colab\n",
    "\n",
    "  ************************************\n",
    "  * A simple working script *\n",
    "  ************************************\n",
    "  ```\n",
    "  import os\n",
    "  import colab_utils.tboard\n",
    "\n",
    "  # set paths\n",
    "  ROOT = %pwd\n",
    "  LOG_DIR = os.path.join(ROOT, 'log')\n",
    "\n",
    "  # will install `ngrok`, if necessary\n",
    "  # will create `log_dir` if path does not exist\n",
    "  tboard.launch_tensorboard( bin_dir=ROOT, log_dir=LOG_DIR )\n",
    "  ```\n",
    "\n",
    "\"\"\"\n",
    "import os\n",
    "import requests\n",
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "__all__ = [\n",
    "  'install_ngrok', \n",
    "  'launch_tensorboard',\n",
    "]\n",
    "\n",
    "def __shell__(cmd, split=True):\n",
    "  # get_ipython().system_raw(cmd)\n",
    "  result = get_ipython().getoutput(cmd, split=split)\n",
    "  if result and not split:\n",
    "    result = result.strip('\\n')\n",
    "  return result  \n",
    "\n",
    "\n",
    "# tested OK\n",
    "def install_ngrok(bin_dir=\"/tmp\"):\n",
    "  \"\"\" download and install ngrok on local vm instance\n",
    "\n",
    "  Args:\n",
    "    bin_dir: full path for the target directory for the `ngrok` binary\n",
    "  \"\"\"\n",
    "  TARGET_DIR = bin_dir\n",
    "  CWD = os.getcwd()\n",
    "  is_grok_avail = os.path.isfile(os.path.join(TARGET_DIR,'ngrok'))\n",
    "  if is_grok_avail:\n",
    "    print(\"ngrok installed\")\n",
    "  else:\n",
    "    import platform\n",
    "    plat = platform.platform() # 'Linux-4.4.64+-x86_64-with-Ubuntu-17.10-artful'\n",
    "    if 'x86_64' in plat:\n",
    "      \n",
    "      os.chdir('/tmp')\n",
    "      print(\"calling wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip ...\" )\n",
    "      get_ipython().system_raw( \"wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\" )\n",
    "      print(\"calling unzip ngrok-stable-linux-amd64.zip ...\")\n",
    "      get_ipython().system_raw( \"unzip ngrok-stable-linux-amd64.zip\" )\n",
    "      os.rename(\"ngrok\", \"{}/ngrok\".format(TARGET_DIR))\n",
    "      os.remove(\"ngrok-stable-linux-amd64.zip\")\n",
    "      is_grok_avail = os.path.isfile(os.path.join(TARGET_DIR,'ngrok'))\n",
    "      os.chdir(TARGET_DIR)\n",
    "      if is_grok_avail:\n",
    "        print(\"ngrok installed. path={}\".format(os.path.join(TARGET_DIR,'ngrok')))\n",
    "      else:\n",
    "        # ValueError: ERROR: ngrok not found, path=\n",
    "        raise ValueError( \"ERROR: ngrok not found, path=\".format(TARGET_DIR) )\n",
    "    else:\n",
    "      raise NotImplementedError( \"ERROR, ngrok install not configured for this platform, platform={}\".format(plat))\n",
    "    os.chdir(CWD)\n",
    "    return\n",
    "    \n",
    "# tested OK\n",
    "def launch_tensorboard(bin_dir=\"/tmp\", log_dir=\"/tmp\", retval=False):\n",
    "  \"\"\"returns a public tensorboard url based on the ngrok package\n",
    "  checks if `ngrok` is available, and installs, if necessary, to `bin_dir`\n",
    "  launches tensorboard, if necessary\n",
    "\n",
    "  see: https://stackoverflow.com/questions/47818822/can-i-use-tensorboard-with-google-colab\n",
    "\n",
    "  Args:\n",
    "    bin_dir: full path for the target directory for the `ngrok` binary\n",
    "    log_dir: full path for the tensorflow `log_dir`\n",
    "\n",
    "  Return:\n",
    "    public url for tensorboard if retval==True\n",
    "      NOTE: the method will print a link to stdout (cell output) for the tensorflow URL. \n",
    "      But the link printed from the return value has an extra \"%27\" in the URL which causes an error\n",
    "\n",
    "  \"\"\"\n",
    "  install_ngrok(bin_dir)\n",
    "    \n",
    "  if not tf.gfile.Exists(log_dir):  tf.gfile.MakeDirs(log_dir)\n",
    "  \n",
    "  # check status of tensorboard and ngrok\n",
    "  ps = __shell__(\"ps -ax\")\n",
    "  is_tensorboard_running = len([f for f in ps if \"tensorboard\" in f ]) > 0\n",
    "  is_ngrok_running = len([f for f in ps if \"ngrok\" in f ]) > 0\n",
    "  print(\"status: tensorboard={}, ngrok={}\".format(is_tensorboard_running, is_ngrok_running))\n",
    "\n",
    "  if not is_tensorboard_running:\n",
    "    get_ipython().system_raw(\n",
    "        'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
    "        .format(log_dir)\n",
    "    )\n",
    "    is_tensorboard_running = True\n",
    "    \n",
    "  if not is_ngrok_running:  \n",
    "    #    grok should be installed in /tmp/ngrok\n",
    "    get_ipython().system_raw('{}/ngrok http 6006 &'.format(bin_dir))\n",
    "    is_ngrok_running = True\n",
    "\n",
    "  # get tensorboard url\n",
    "  # BUG: getting connection refused for HTTPConnectionPool(host='localhost', port=4040)\n",
    "  #     on first run, retry works\n",
    "  import time\n",
    "  time.sleep(3)\n",
    "  retval = requests.get('http://localhost:4040/api/tunnels')\n",
    "  tensorboard_url = retval.json()['tunnels'][0]['public_url'].strip()\n",
    "  print(\"tensorboard url=\", tensorboard_url)\n",
    "  if retval:\n",
    "    return tensorboard_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "SZlqMZRs9IsB"
   },
   "outputs": [],
   "source": [
    "# launch tensorboard\n",
    "root_dir=%pwd\n",
    "log_dir=root_dir+'/stereo_model1'\n",
    "launch_tensorboard(bin_dir=root_dir,log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uDaxBBz8Mx_1"
   },
   "source": [
    "The following are some useful shell commands to check tensorboard status and remove/download training checkpoints as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Ngn4OOIDbpxp"
   },
   "outputs": [],
   "source": [
    "#!ps ax | grep tensorboard\n",
    "#!ps ax | grep ngrok\n",
    "\n",
    "#!ls {log_dir}\n",
    "#!rm -r {log_dir}/*\n",
    "\n",
    "#from google.colab import files\n",
    "\n",
    "#!zip -r log_dir.zip {log_dir} \n",
    "#files.download('log_dir.zip')\n",
    "\n",
    "#uploaded = files.upload()\n",
    "#!unzip log_dir.zip \n",
    "#!mv content/* .\n",
    "#!rmdir content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jDEpFTb4VEPj"
   },
   "source": [
    "## Define Stereo Model [25%]\n",
    "\n",
    "Now define a Tensorflow model that takes the block matching cost volume as input and filters it using a convolutional network to estimate the depth. Your model should output a `pred` tensor containing disparity estimates, this should be the same shape as the `target_disp`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "-YfbaC2ceDwq"
   },
   "outputs": [],
   "source": [
    "def stereo_model1(features,labels,mode):\n",
    "  input_data=features\n",
    "  target_disp=labels\n",
    "  \n",
    "  # FORNOW: predict single value for depth\n",
    "  pred = tf.zeros_like(tf.expand_dims(input_data[:,:,:,0],3))\n",
    "  pred = tf.contrib.layers.bias_add(pred)\n",
    "  \n",
    "  # TODO: set border width to exclude edge pixels that are invalid due to convolution\n",
    "  border_width=3 \n",
    "  \n",
    "  \"\"\"\n",
    "  *********************************************\n",
    "  *** TODO: define a model for depth estimation\n",
    "  *********************************************\n",
    "\n",
    "  Inputs: input_data=input features (B, H, W, NF)\n",
    "          target_disp=disparity ground truth (B, H, W, 1)\n",
    "\n",
    "  Outputs: pred=disparity predictions (B, H, W, 1)\n",
    "  \"\"\"\n",
    "    \n",
    "  \n",
    "  \n",
    "  \"\"\"\n",
    "  *********************************************\n",
    "  \"\"\"\n",
    "    \n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=pred)\n",
    "\n",
    "  # don't compute loss where there is no ground truth,\n",
    "  # or over invalid part of convolution\n",
    "  valid=tf.to_float(tf.greater(target_disp,0.01))\n",
    "  \n",
    "  N=border_width\n",
    "  if (N>1):\n",
    "    paddings=[[0,0],[N,N],[N,N],[0,0]]\n",
    "    border=tf.pad(tf.ones_like(target_disp[:,N:-N,N:-N,:]),paddings)\n",
    "    valid=valid*border\n",
    "\n",
    "  # block matching loss\n",
    "  cost_volume=input_data\n",
    "  block_estimate=tf.argmin(cost_volume,axis=3)\n",
    "  block_estimate=tf.to_float(tf.expand_dims(block_estimate,3))\n",
    "  \n",
    "  # loss\n",
    "  loss = tf.losses.mean_squared_error(target_disp,pred,weights=valid)\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    #optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "    train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "    tf.summary.image(\"pred\",pred)\n",
    "    tf.summary.image(\"target\",target_disp)\n",
    "    tf.summary.image(\"block\",block_estimate)\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "  # if mode == tf.estimator.ModeKeys.EVAL\n",
    "  mse=tf.metrics.mean_squared_error(target_disp,pred,weights=valid)\n",
    "  block=tf.metrics.mean_squared_error(target_disp,block_estimate,weights=valid)\n",
    "\n",
    "  eval_metric_ops = {\"mse\": mse, \"block\": block}\n",
    "  tf.summary.scalar(\"mse\", mse[1])\n",
    "  tf.summary.scalar(\"block\", block[1])\n",
    "  \n",
    "  return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QedTefLcVMIA"
   },
   "source": [
    "## Train and Evaluate Model [35%]\n",
    "\n",
    "Now, train your model using the `tf.estimator.train_and_evaluate` function. A good baseline for comparison is the performance of the block matching estimate, reported as `block` in Tensorboard. Experiment with your model configuration, inputs and parameter settings to try to get a good stereo estimates. Record your findings in the notebook below. Note: if you change the model, you will need to erase previous checkpoints using the shell commands above. Also, if you model is large it probably will run faster if you set the runtime to GPU, via the Runtime->Change Runtime Type menu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_OSjkab-aWcm"
   },
   "outputs": [],
   "source": [
    "data_dir=\"kitti_stereo2012/training\"\n",
    "\n",
    "num_data=194\n",
    "num_eval=15\n",
    "num_train=num_data-num_eval\n",
    "train_ids=np.arange(0,num_train)\n",
    "eval_ids=np.arange(num_train,num_train+num_eval)\n",
    "\n",
    "train_data=get_kitti_2012_dataset(train_ids, data_dir)\n",
    "eval_data=get_kitti_2012_dataset(eval_ids, data_dir)\n",
    "\n",
    "# create model\n",
    "stereo_regressor = tf.estimator.Estimator(\n",
    "    model_fn=stereo_model1, model_dir=log_dir)\n",
    "\n",
    "# train model\n",
    "train_spec = tf.estimator.TrainSpec(input_fn=train_data.get_batch, max_steps=100000)\n",
    "eval_spec = tf.estimator.EvalSpec(input_fn=eval_data.get_batch, steps=1000, start_delay_secs=0, throttle_secs=120)\n",
    "tf.estimator.train_and_evaluate(stereo_regressor, train_spec, eval_spec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X5AxHXLCVP85"
   },
   "source": [
    "## Results\n",
    "\n",
    "The code below performs inference using the model on full size images from the eval set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "DqxdGP6VaWcq"
   },
   "outputs": [],
   "source": [
    "pred=stereo_regressor.predict(input_fn=eval_data.get_preprocessed_images)\n",
    "\n",
    "num_eval=4\n",
    "plt.rcParams['figure.figsize'] = (16.0, num_eval*4.0)\n",
    "\n",
    "for i in range(num_eval):\n",
    "  img_pred=next(pred)\n",
    "  plt.subplot(num_eval,1,i+1)\n",
    "  plt.imshow(grey_to_rgb(normalise_01(img_pred)))\n",
    "  plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "wxBmyFTTz2CQ"
   ],
   "default_view": {},
   "name": "Project4.ipynb",
   "provenance": [
    {
     "file_id": "1dw6C1MN72Y2qPtNNWPiVp9tqInRHZCdg",
     "timestamp": 1526499883112
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
